{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kernel_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-7bfdb1c0c41b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_strides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kernel_sizes' is not defined"
     ]
    }
   ],
   "source": [
    "assert(len(kernel_sizes)==len(filter_sizes)==len(conv_strides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3,4],[4,5,6,4],[1,8,9,4],[0,0,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 3\n",
    "y, x = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(0, s, dtype=torch.float32),\n",
    "                torch.arange(0, s, dtype=torch.float32),\n",
    "            ])\n",
    "y, x = y.contiguous(), x.contiguous()\n",
    "y, x = y.view(s *s), x.view(s * s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 0., 1., 2., 0., 1., 2.],\n",
       "        [0., 0., 0., 1., 1., 1., 2., 2., 2.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.vstack((x,y, torch.ones(x.shape)))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 9])\n",
      "tensor([[[0., 1., 2., 0., 1., 2., 0., 1., 2.],\n",
      "         [0., 0., 0., 1., 1., 1., 2., 2., 2.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 1., 2., 0., 1., 2., 0., 1., 2.],\n",
      "         [0., 0., 0., 1., 1., 1., 2., 2., 2.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
      "tensor([[[ 1.,  0.,  0.],\n",
      "         [ 0.,  0., -1.],\n",
      "         [ 0.,  1.,  0.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0.,  0., -1.],\n",
      "         [ 0.,  1.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "# add the batch dimension\n",
    "# p: [3,H*W] -> [B,3,H*W] \n",
    "B = 2\n",
    "p = torch.unsqueeze(p,0)\n",
    "# repeat B time\n",
    "p = p.repeat((B,1,1))\n",
    "print(p.shape)\n",
    "print(p)\n",
    "R = torch.tensor([[1.,0.,0.],[0.,0,-1.],[0,1,0]])\n",
    "R = torch.unsqueeze(R,0)\n",
    "R = R.repeat((B,1,1))\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "p_R = torch.matmul(R,p)\n",
    "print(p_R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3, 9])\n",
      "torch.Size([2, 2, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "p_Rd = torch.unsqueeze(p_R,1)\n",
    "print(p_Rd.shape)\n",
    "D = 2\n",
    "p_Rd = p_Rd.repeat((1,D,1,1))\n",
    "print(p_Rd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]],\n",
       "\n",
       "         [[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]],\n",
       "\n",
       "         [[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]]]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7],\n",
      "         [6],\n",
      "         [0]],\n",
      "\n",
      "        [[9],\n",
      "         [0],\n",
      "         [5]]])\n",
      "torch.Size([2, 3, 1, 1])\n",
      "tensor([[[[7]],\n",
      "\n",
      "         [[6]],\n",
      "\n",
      "         [[0]]],\n",
      "\n",
      "\n",
      "        [[[9]],\n",
      "\n",
      "         [[0]],\n",
      "\n",
      "         [[5]]]])\n",
      "torch.Size([2, 3, 4, 9])\n",
      "tensor([[[[1, 7, 1, 4, 6, 6, 0, 6, 5],\n",
      "          [7, 9, 8, 7, 2, 4, 7, 1, 9],\n",
      "          [0, 1, 3, 5, 1, 8, 6, 7, 8],\n",
      "          [8, 4, 1, 7, 3, 3, 6, 7, 6]],\n",
      "\n",
      "         [[0, 6, 6, 6, 4, 0, 9, 3, 9],\n",
      "          [3, 3, 1, 0, 8, 8, 3, 7, 8],\n",
      "          [2, 9, 5, 1, 2, 2, 3, 0, 3],\n",
      "          [4, 5, 2, 1, 4, 2, 9, 4, 3]],\n",
      "\n",
      "         [[9, 6, 0, 2, 4, 3, 7, 6, 4],\n",
      "          [7, 4, 0, 7, 3, 7, 0, 8, 1],\n",
      "          [5, 1, 1, 9, 6, 6, 6, 5, 1],\n",
      "          [0, 5, 1, 3, 1, 7, 4, 8, 9]]],\n",
      "\n",
      "\n",
      "        [[[3, 6, 0, 6, 3, 5, 0, 5, 8],\n",
      "          [1, 9, 3, 8, 8, 0, 3, 8, 1],\n",
      "          [9, 8, 1, 9, 7, 8, 4, 5, 2],\n",
      "          [7, 7, 7, 5, 0, 2, 2, 8, 3]],\n",
      "\n",
      "         [[9, 0, 1, 6, 2, 3, 5, 8, 4],\n",
      "          [2, 1, 5, 9, 1, 1, 5, 3, 4],\n",
      "          [3, 9, 7, 3, 2, 0, 8, 5, 2],\n",
      "          [7, 2, 9, 3, 0, 6, 6, 9, 7]],\n",
      "\n",
      "         [[1, 0, 8, 0, 5, 1, 0, 3, 0],\n",
      "          [3, 7, 3, 5, 3, 9, 5, 8, 8],\n",
      "          [2, 0, 1, 9, 8, 0, 9, 4, 1],\n",
      "          [9, 8, 2, 0, 9, 2, 0, 6, 4]]]])\n",
      "tensor([[[[ 8, 14,  8, 11, 13, 13,  7, 13, 12],\n",
      "          [14, 16, 15, 14,  9, 11, 14,  8, 16],\n",
      "          [ 7,  8, 10, 12,  8, 15, 13, 14, 15],\n",
      "          [15, 11,  8, 14, 10, 10, 13, 14, 13]],\n",
      "\n",
      "         [[ 6, 12, 12, 12, 10,  6, 15,  9, 15],\n",
      "          [ 9,  9,  7,  6, 14, 14,  9, 13, 14],\n",
      "          [ 8, 15, 11,  7,  8,  8,  9,  6,  9],\n",
      "          [10, 11,  8,  7, 10,  8, 15, 10,  9]],\n",
      "\n",
      "         [[ 9,  6,  0,  2,  4,  3,  7,  6,  4],\n",
      "          [ 7,  4,  0,  7,  3,  7,  0,  8,  1],\n",
      "          [ 5,  1,  1,  9,  6,  6,  6,  5,  1],\n",
      "          [ 0,  5,  1,  3,  1,  7,  4,  8,  9]]],\n",
      "\n",
      "\n",
      "        [[[12, 15,  9, 15, 12, 14,  9, 14, 17],\n",
      "          [10, 18, 12, 17, 17,  9, 12, 17, 10],\n",
      "          [18, 17, 10, 18, 16, 17, 13, 14, 11],\n",
      "          [16, 16, 16, 14,  9, 11, 11, 17, 12]],\n",
      "\n",
      "         [[ 9,  0,  1,  6,  2,  3,  5,  8,  4],\n",
      "          [ 2,  1,  5,  9,  1,  1,  5,  3,  4],\n",
      "          [ 3,  9,  7,  3,  2,  0,  8,  5,  2],\n",
      "          [ 7,  2,  9,  3,  0,  6,  6,  9,  7]],\n",
      "\n",
      "         [[ 6,  5, 13,  5, 10,  6,  5,  8,  5],\n",
      "          [ 8, 12,  8, 10,  8, 14, 10, 13, 13],\n",
      "          [ 7,  5,  6, 14, 13,  5, 14,  9,  6],\n",
      "          [14, 13,  7,  5, 14,  7,  5, 11,  9]]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randint(low=0,high=10,size=(2,3,1))\n",
    "print(t)\n",
    "t = t.view(2,3,1,1)\n",
    "print(t.shape)\n",
    "print(t)\n",
    "r = torch.randint(low=0,high=10, size=(2,3,4,9)) # [B,3,D,H*W]\n",
    "print(r.shape)\n",
    "print(r)\n",
    "\n",
    "proj_xyz = r + t\n",
    "print(proj_xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiplication elementwise with depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]],\n",
       "\n",
       "         [[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]],\n",
       "\n",
       "         [[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]]]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_Rd.shape)\n",
    "p_Rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4],\n",
      "        [1, 2]])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "depth_values = torch.randint(low=1, high=5, size=(B,D))\n",
    "print(depth_values)\n",
    "print(depth_values.shape)\n",
    "depth_values = torch.unsqueeze(depth_values,2)\n",
    "depth_values = torch.unsqueeze(depth_values,3)\n",
    "print(depth_values.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  4.,  8.,  0.,  4.,  8.,  0.,  4.,  8.],\n",
       "          [-4., -4., -4., -4., -4., -4., -4., -4., -4.],\n",
       "          [ 0.,  0.,  0.,  4.,  4.,  4.,  8.,  8.,  8.]],\n",
       "\n",
       "         [[ 0.,  4.,  8.,  0.,  4.,  8.,  0.,  4.,  8.],\n",
       "          [-4., -4., -4., -4., -4., -4., -4., -4., -4.],\n",
       "          [ 0.,  0.,  0.,  4.,  4.,  4.,  8.,  8.,  8.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  0.,  1.,  2.,  0.,  1.,  2.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]],\n",
       "\n",
       "         [[ 0.,  2.,  4.,  0.,  2.,  4.,  0.,  2.,  4.],\n",
       "          [-2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
       "          [ 0.,  0.,  0.,  2.,  2.,  2.,  4.,  4.,  4.]]]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uvd_b_rot = p_Rd*depth_values\n",
    "uvd_b_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "tensor([[[3],\n",
      "         [1],\n",
      "         [3]],\n",
      "\n",
      "        [[1],\n",
      "         [2],\n",
      "         [1]]])\n"
     ]
    }
   ],
   "source": [
    "trans = torch.randint(low=1, high=4, size=(B,3,1))\n",
    "print(trans.shape)\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[3]],\n",
       "\n",
       "         [[1]],\n",
       "\n",
       "         [[3]]],\n",
       "\n",
       "\n",
       "        [[[1]],\n",
       "\n",
       "         [[2]],\n",
       "\n",
       "         [[1]]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans1 = trans.view(B,3,1,1)\n",
    "print(trans1.shape)\n",
    "trans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[3],\n",
       "          [1],\n",
       "          [3]]],\n",
       "\n",
       "\n",
       "        [[[1],\n",
       "          [2],\n",
       "          [1]]]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans2 = torch.unsqueeze(trans,1)\n",
    "print(trans2.shape)\n",
    "trans2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: it doesn't matter whether you use view or unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 9])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uvd_b_rot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3, 1])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.,  7., 11.,  3.,  7., 11.,  3.,  7., 11.],\n",
       "          [-3., -3., -3., -3., -3., -3., -3., -3., -3.],\n",
       "          [ 3.,  3.,  3.,  7.,  7.,  7., 11., 11., 11.]],\n",
       "\n",
       "         [[ 3.,  7., 11.,  3.,  7., 11.,  3.,  7., 11.],\n",
       "          [-3., -3., -3., -3., -3., -3., -3., -3., -3.],\n",
       "          [ 3.,  3.,  3.,  7.,  7.,  7., 11., 11., 11.]]],\n",
       "\n",
       "\n",
       "        [[[ 1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  2.,  2.,  2.,  3.,  3.,  3.]],\n",
       "\n",
       "         [[ 1.,  3.,  5.,  1.,  3.,  5.,  1.,  3.,  5.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 1.,  1.,  1.,  3.,  3.,  3.,  5.,  5.,  5.]]]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uvd_b_rot+trans2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test warping function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warping function from git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiable_warping(\n",
    "    src_fea: torch.Tensor, src_proj: torch.Tensor, ref_proj: torch.Tensor, depth_samples: torch.Tensor\n",
    "):\n",
    "    \"\"\"Differentiable homography-based warping, implemented in Pytorch.\n",
    "    Args:\n",
    "        src_fea: [B, C, H, W] source features, for each source view in batch\n",
    "        src_proj: [B, 4, 4] source camera projection matrix, for each source view in batch\n",
    "        ref_proj: [B, 4, 4] reference camera projection matrix, for each ref view in batch\n",
    "        depth_samples: [B, Ndepth, H, W] virtual depth layers\n",
    "    Returns:\n",
    "        warped_src_fea: [B, C, Ndepth, H, W] features on depths after perspective transformation\n",
    "    \"\"\"\n",
    "\n",
    "    batch, channels, height, width = src_fea.shape\n",
    "    num_depth = depth_samples.shape[1]\n",
    "    \n",
    "    ## to align with my function\n",
    "#     depth_samples = depth_samples[:,:,1,1]\n",
    "#     depth_samples = torch.squeeze(depth_samples)\n",
    "#     print(\"depth sample shape [B,D]: \",depth_sample.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        proj = torch.matmul(src_proj, torch.inverse(ref_proj))\n",
    "        rot = proj[:, :3, :3]  # [B,3,3]\n",
    "        trans = proj[:, :3, 3:4]  # [B,3,1]\n",
    "\n",
    "        y, x = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(0, height, dtype=torch.float32, device=src_fea.device),\n",
    "                torch.arange(0, width, dtype=torch.float32, device=src_fea.device),\n",
    "            ]\n",
    "        )\n",
    "        y, x = y.contiguous(), x.contiguous()\n",
    "        y, x = y.view(height * width), x.view(height * width)\n",
    "        xyz = torch.stack((x, y, torch.ones_like(x)))  # [3, H*W]\n",
    "        xyz = torch.unsqueeze(xyz, 0).repeat(batch, 1, 1)  # [B, 3, H*W]\n",
    "        rot_xyz = torch.matmul(rot, xyz)  # [B, 3, H*W]\n",
    "        \n",
    "        a = rot_xyz.unsqueeze(2).repeat(1, 1, num_depth, 1)\n",
    "        print(\"a\",a.shape)\n",
    "        print(\"depth_samples\", depth_samples.shape)\n",
    "        b = depth_samples.view(batch, 1, num_depth, height * width)\n",
    "        print(\"b\",b.shape)\n",
    "        rot_depth_xyz = a * b  # [B, 3, Ndepth, H*W]\n",
    "#         rot_depth_xyz = rot_xyz.unsqueeze(1).repeat(1, num_depth, 1, 1) * depth_samples.view(\n",
    "#             batch, 1, 3, 1\n",
    "#         )\n",
    "        proj_xyz = rot_depth_xyz + trans.view(batch, 3, 1, 1)  # [B, 3, Ndepth, H*W]\n",
    "#         # avoid negative depth\n",
    "#         negative_depth_mask = proj_xyz[:, 2:] <= 1e-3\n",
    "#         proj_xyz[:, 0:1][negative_depth_mask] = float(width)\n",
    "#         proj_xyz[:, 1:2][negative_depth_mask] = float(height)\n",
    "#         proj_xyz[:, 2:3][negative_depth_mask] = 1.0\n",
    "#         proj_xy = proj_xyz[:, :2, :, :] / proj_xyz[:, 2:3, :, :]  # [B, 2, Ndepth, H*W]\n",
    "#         proj_x_normalized = proj_xy[:, 0, :, :] / ((width - 1) / 2) - 1  # [B, Ndepth, H*W]\n",
    "#         proj_y_normalized = proj_xy[:, 1, :, :] / ((height - 1) / 2) - 1\n",
    "#         proj_xy = torch.stack((proj_x_normalized, proj_y_normalized), dim=3)  # [B, Ndepth, H*W, 2]\n",
    "#         grid = proj_xy\n",
    "\n",
    "#     warped_src_fea = F.grid_sample(\n",
    "#         src_fea,\n",
    "#         grid.view(batch, num_depth * height, width, 2),\n",
    "#         mode=\"bilinear\",\n",
    "#         padding_mode=\"zeros\",\n",
    "#         align_corners=True,\n",
    "#     )\n",
    "\n",
    "#     return warped_src_fea.view(batch, channels, num_depth, height, width)\n",
    "\n",
    "    return proj_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My warping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warping(src_fea, src_proj, ref_proj, depth_values):\n",
    "    # src_fea: [B, C, H, W], B,32,160,128\n",
    "    # src_proj: [B, 4, 4], Projection matrix 4x4\n",
    "    # ref_proj: [B, 4, 4], Projection matrix 4x4\n",
    "    # depth_values: [B, D]\n",
    "    # out: [B, C, D, H, W]\n",
    "    B,C,H,W = src_fea.size()\n",
    "    D = depth_values.size(1)\n",
    "    print(\"depth_values\",depth_values)\n",
    "    # compute the warped positions with depth values\n",
    "    with torch.no_grad():\n",
    "        # relative transformation from reference to source view\n",
    "        proj = torch.matmul(src_proj, torch.inverse(ref_proj))\n",
    "        rot = proj[:, :3, :3]  # [B,3,3]\n",
    "        print(\"rot\",rot)\n",
    "        trans = proj[:, :3, 3:4]  # [B,3,1]\n",
    "        print(\"trans\",trans)\n",
    "        y, x = torch.meshgrid([torch.arange(0, H, dtype=torch.float32, device=src_fea.device),\n",
    "                               torch.arange(0, W, dtype=torch.float32, device=src_fea.device)])\n",
    "        y, x = y.contiguous(), x.contiguous() # memory reshape\n",
    "        y, x = y.view(H * W), x.view(H * W) # reshape tensor\n",
    "        # TODO\n",
    "        # stack all reference image pixel coordinates\n",
    "        uv1 = torch.vstack((x, y, torch.ones(x.shape))) # [3,H*W]\n",
    "        # add batch dimension\n",
    "        print(\"uv1\",uv1)\n",
    "        uv1_b = torch.unsqueeze(uv1, 0).repeat((B, 1, 1))  # [B,3,H*W]\n",
    "        print(\"uv1_b\",uv1_b)\n",
    "\n",
    "        # rotate\n",
    "        uv1_b_rot = torch.matmul(rot,uv1_b)\n",
    "        print(\"uv1_b_rot\",uv1_b_rot)   \n",
    "        \n",
    "        # add depth dimension\n",
    "        uvd_b_rot = torch.unsqueeze(uv1_b_rot, 1).repeat((1, D, 1, 1))  # [B,D,3,H*W]\n",
    "        print(\"uvd_b_rot prev\",uvd_b_rot)\n",
    "        # multiply with depth samples\n",
    "        depth_values = torch.unsqueeze(depth_values,2)\n",
    "        depth_values = torch.unsqueeze(depth_values, 3) # [B,D,1,1]\n",
    "        uvd_b_rot = uvd_b_rot*depth_values # elementwise multiplication along dimension [-,-,3,H*W]; [B,D,3,H*W]\n",
    "        print(\"uvd_b_rot\",uvd_b_rot)\n",
    "        # translate\n",
    "        trans = torch.unsqueeze(trans,1) # [B,1,3,1]\n",
    "        uvd_b_rot_trans = uvd_b_rot + trans # [B,D,3,H*W]\n",
    "        print(\"trans\",trans)\n",
    "        print(\"uvd_b_rot_trans\",uvd_b_rot_trans)\n",
    "\n",
    "     # get warped_src_fea with bilinear interpolation (use 'grid_sample' function from pytorch)\n",
    "     # TODO\n",
    "\n",
    "    return uvd_b_rot_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_values tensor([[0, 2, 1],\n",
      "        [2, 2, 2]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'warping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-be323f678483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"depth_values\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmy_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# their_pixels = differentiable_warping(src_feat, T_src, T_ref, depth_values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warping' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "# create input data\n",
    "B,C,H,W = 2,3,2,2\n",
    "D=3\n",
    "src_feat = torch.randint(low=0, high=10, size=(B,C,H,W))\n",
    "R_src = torch.eye(3)\n",
    "R_ref = torch.tensor([[ 1.0000000,  0.0000000,  0.0000000],[0.0000000,  0.9848077, -0.1736482],[0.0000000,  0.1736482,  0.9848077]])\n",
    "t_src = torch.zeros((1,3))\n",
    "t_ref = torch.tensor([0.2,0.3,0.1])\n",
    "T_src = torch.zeros((4,4))\n",
    "T_ref = torch.zeros((4,4))\n",
    "T_src[0:3,0:3] = R_src\n",
    "T_ref[0:3,0:3] = R_ref\n",
    "T_src[0:3,3] = t_src\n",
    "T_ref[0:3,3] = t_ref\n",
    "T_src[3,3] = 1\n",
    "T_ref[3,3] = 1\n",
    "\n",
    "T_src = torch.unsqueeze(T_src,0).repeat((B,1,1))\n",
    "T_ref = torch.unsqueeze(T_ref,0).repeat((B,1,1))\n",
    "\n",
    "depth_values = torch.randint(low=0, high=4, size=(B,D))\n",
    "print(\"depth_values\",depth_values)\n",
    "\n",
    "my_pixels = warping(src_feat, T_src, T_ref, depth_values) \n",
    "print(my_pixels)\n",
    "# their_pixels = differentiable_warping(src_feat, T_src, T_ref, depth_values)\n",
    "# print(their_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_features torch.Size([2, 3, 2, 2])\n",
      "warped_src_features:  torch.Size([2, 3, 3, 2, 2])\n",
      "------------------------------\n",
      "ref_feature torch.Size([3, 2, 2])\n",
      "warped_src_feature torch.Size([3, 3, 2, 2])\n",
      "**************\n",
      "ref_feature torch.Size([3, 2, 2])\n",
      "warped_src_feature torch.Size([3, 3, 2, 2])\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "B,C,H,W = 2,3,2,2\n",
    "D=3\n",
    "warped_src_features = torch.randint(low=0, high=5, size=(B,C,D,H,W))\n",
    "\n",
    "ref_features = torch.randint(low=0, high=5, size=(B,C,H,W))\n",
    "print(\"ref_features\",ref_features.shape)\n",
    "print(\"warped_src_features: \",warped_src_features.shape)\n",
    "print(\"------------------------------\")\n",
    "\n",
    "for ref_feature, warped_src_feature in zip(ref_features, warped_src_features):\n",
    "    print(\"ref_feature\",ref_feature.shape)\n",
    "    print(\"warped_src_feature\",warped_src_feature.shape)\n",
    "    print(\"**************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_conv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_conv.append(3)\n",
    "layers_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = np.empty(0)\n",
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
